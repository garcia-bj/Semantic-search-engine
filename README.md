# Buscador SemÃ¡ntico - Motor de BÃºsqueda Avanzado

Sistema completo de bÃºsqueda semÃ¡ntica para bases de conocimiento OWL/RDF con capacidades avanzadas de indexaciÃ³n, bÃºsqueda multilingÃ¼e, y funcionalidad offline.

## ğŸŒŸ CaracterÃ­sticas Principales

### ğŸ” BÃºsqueda Avanzada
- **6 tipos de bÃºsqueda SPARQL**: Simple, por sujeto/predicado/objeto, por patrÃ³n, difusa
- **Elasticsearch integrado**: BÃºsquedas 10-20x mÃ¡s rÃ¡pidas
- **Autocompletado inteligente**: Sugerencias mientras escribes
- **Ranking semÃ¡ntico**: TF-IDF + BM25 para resultados relevantes
- **WebSocket**: Resultados en tiempo real

### ğŸŒ MultilingÃ¼e
- **EspaÃ±ol** (por defecto)
- **InglÃ©s**
- DetecciÃ³n automÃ¡tica del navegador
- FÃ¡cil agregar mÃ¡s idiomas

### ğŸ“± PWA (Progressive Web App)
- **Funciona offline**: Sin conexiÃ³n a internet
- **Instalable**: Como app nativa en dispositivos
- **SincronizaciÃ³n automÃ¡tica**: Al reconectar
- **Service Worker**: CachÃ© inteligente

### ğŸ—„ï¸ Almacenamiento HÃ­brido
- **PostgreSQL**: Metadatos de documentos
- **Apache Fuseki**: Triple store nativo para RDF
- **Elasticsearch**: Ãndice full-text optimizado
- **IndexedDB**: Almacenamiento local offline

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Frontend (PWA)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Service Worker       â”‚ â”‚
â”‚  â”‚   IndexedDB            â”‚ â”‚
â”‚  â”‚   i18n (ES/EN)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP + WebSocket
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Backend (NestJS)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SearchService         â”‚  â”‚
â”‚  â”‚  - Semantic Ranking    â”‚  â”‚
â”‚  â”‚  - SPARQL Queries      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  OntologyService       â”‚  â”‚
â”‚  â”‚  - RDF Parsing         â”‚  â”‚
â”‚  â”‚  - Auto-indexing       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚              â”‚              â”‚
    â–¼             â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Postgres â”‚  â”‚ Fuseki  â”‚  â”‚Elasticsearch â”‚  â”‚IndexedDB â”‚
â”‚(Meta)   â”‚  â”‚(Triples)â”‚  â”‚(Full-text)   â”‚  â”‚(Offline) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- **Node.js** v18 o superior
- **Docker** y Docker Compose
- **npm** o **yarn**

### Paso 1: Clonar el Repositorio
```bash
git clone <url-del-repositorio>
cd BUSCADOR_SEMANTICO
```

### Paso 2: Iniciar Servicios con Docker
```bash
cd backend
docker-compose up -d
```

Esto iniciarÃ¡:
- **PostgreSQL** (puerto 5433)
- **Apache Fuseki** (puerto 3030)
- **Elasticsearch** (puerto 9200)

### Paso 3: Configurar Fuseki
1. Accede a http://localhost:3030
2. Usuario: `admin`, ContraseÃ±a: `admin123`
3. Click en "Manage datasets" â†’ "Add new dataset"
4. Dataset name: `semantic-search`
5. Dataset type: "Persistent (TDB2)"
6. Click "Create dataset"

### Paso 4: Configurar Backend
```bash
cd backend
npm install

# Configurar variables de entorno
# El archivo .env.example contiene las configuraciones necesarias
# Copiar y ajustar si es necesario:
# cp .env.example .env

# Generar el cliente de Prisma
npx prisma generate

# Ejecutar migraciÃ³n de base de datos
npx prisma db push

# Iniciar servidor de desarrollo
npm run start:dev
```

El backend estarÃ¡ disponible en http://localhost:3001

> **Nota importante**: Si encuentras el error "tripleCount no existe en el tipo DocumentCreateInput", ejecuta `npx prisma generate` para regenerar el cliente de Prisma.

### Paso 5: Configurar Frontend
```bash
cd ../frontend
npm install

# Iniciar servidor de desarrollo
npm run dev
```

El frontend estarÃ¡ disponible en http://localhost:3000

---

## ğŸ”§ SoluciÃ³n de Problemas Comunes

### Error: "tripleCount no existe en el tipo DocumentCreateInput"
**Causa**: El cliente de Prisma estÃ¡ desactualizado.

**SoluciÃ³n**:
```bash
cd backend
npx prisma generate
```

### Error: "Port 3001 is already in use"
**Causa**: Ya hay un proceso usando el puerto 3001.

**SoluciÃ³n**:
```bash
# Windows
netstat -ano | findstr :3001
taskkill /F /PID <PID>

# Linux/Mac
lsof -ti:3001 | xargs kill -9
```

### Error al iniciar Docker
**Causa**: Docker no estÃ¡ corriendo o hay conflictos de puertos.

**SoluciÃ³n**:
1. Verifica que Docker Desktop estÃ© corriendo
2. Verifica que los puertos 5433, 3030 y 9200 estÃ©n disponibles
3. Reinicia los contenedores:
```bash
cd backend
docker-compose down
docker-compose up -d
```

### El backend no se conecta a Fuseki
**Causa**: El dataset no estÃ¡ creado en Fuseki.

**SoluciÃ³n**:
1. Accede a http://localhost:3030
2. Verifica que exista el dataset `semantic-search`
3. Si no existe, crÃ©alo siguiendo el Paso 3 de instalaciÃ³n

---

## ğŸ“š API Endpoints

### BÃºsqueda

#### BÃºsqueda Simple
```bash
GET /search?q=term&lang=es
```

#### BÃºsqueda RÃ¡pida (Elasticsearch)
```bash
GET /search/fast?q=term&lang=es
```

#### Autocompletado
```bash
GET /search/autocomplete?q=fu
```

#### BÃºsqueda por Sujeto
```bash
GET /search/subject?uri=http://example.org/subject
```

#### BÃºsqueda por Predicado
```bash
GET /search/predicate?uri=http://example.org/predicate
```

#### BÃºsqueda por Objeto
```bash
GET /search/object?value=someValue
```

#### BÃºsqueda Difusa
```bash
GET /search/fuzzy?q=term&threshold=0.7&lang=es
```

#### BÃºsqueda por PatrÃ³n
```bash
POST /search/pattern
Content-Type: application/json

{
  "subject": "http://example.org/Subject",
  "predicate": "http://example.org/predicate",
  "object": "value",
  "language": "es"
}
```

### WebSocket

```javascript
import io from 'socket.io-client';

const socket = io('http://localhost:3001');

// Enviar bÃºsqueda
socket.emit('search:query', {
  query: 'fuego',
  language: 'es',
  type: 'simple'
});

// Recibir progreso
socket.on('search:progress', (data) => {
  console.log(data.message);
});

// Recibir resultados
socket.on('search:results', (data) => {
  console.log(data.results);
});

// BÃºsqueda completada
socket.on('search:complete', (data) => {
  console.log(data.message);
});
```

### GestiÃ³n de Documentos

#### Subir Documento OWL/RDF
```bash
POST /upload
Content-Type: multipart/form-data

file: <archivo.owl>
```

#### Listar Documentos
```bash
GET /upload/documents
```

#### Eliminar Documento
```bash
DELETE /upload/:id
```

---

## ğŸŒ Uso

### 1. Subir Base de Conocimiento
1. Ve a la secciÃ³n **Base de Conocimiento**
2. Click en **Subir OWL/RDF**
3. Selecciona tu archivo `.owl` o `.rdf`
4. El sistema automÃ¡ticamente:
   - Parsea el archivo (rdflib)
   - Guarda metadatos en PostgreSQL
   - Almacena tripletas en Fuseki
   - Indexa en Elasticsearch

### 2. Realizar BÃºsquedas
1. Ve al **Buscador**
2. Escribe tu consulta
3. Selecciona idioma (opcional)
4. ObtÃ©n resultados ordenados por relevancia

### 3. Cambiar Idioma
- Click en el selector de idioma (ğŸ‡ªğŸ‡¸/ğŸ‡¬ğŸ‡§)
- O navega a `/es` o `/en`

### 4. Usar Offline
1. Visita la aplicaciÃ³n online
2. Desconecta internet
3. La app sigue funcionando
4. Los cambios se sincronizan al reconectar

### 5. Instalar como App
1. Chrome: Click en "Instalar Buscador SemÃ¡ntico"
2. La app se abre como aplicaciÃ³n nativa
3. Funciona offline

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend
- **NestJS** - Framework Node.js
- **Apache Fuseki** - Triple store RDF
- **Elasticsearch** - Motor de bÃºsqueda
- **SPARQL** - Lenguaje de consulta RDF
- **Prisma** - ORM para PostgreSQL
- **PostgreSQL** - Base de datos relacional
- **rdflib** - Parser RDF/OWL
- **Socket.io** - WebSocket
- **nestjs-i18n** - InternacionalizaciÃ³n

### Frontend
- **Next.js 16** - Framework React
- **React 19** - Biblioteca UI
- **TailwindCSS 4** - Estilos
- **TypeScript** - Tipado estÃ¡tico
- **next-i18next** - i18n
- **idb** - IndexedDB
- **Socket.io-client** - WebSocket

### Infraestructura
- **Docker** - ContenerizaciÃ³n
- **Docker Compose** - OrquestaciÃ³n

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno (Backend)

Crea un archivo `.env` en el directorio `backend` con el siguiente contenido:

```env
# Base de datos
DATABASE_URL="postgresql://semantic_user:semantic_password@localhost:5433/semantic_search"

# Fuseki
FUSEKI_URL="http://localhost:3030"
FUSEKI_DATASET="semantic-search"
FUSEKI_USERNAME="admin"
FUSEKI_PASSWORD="admin123"

# Elasticsearch
ELASTICSEARCH_URL="http://localhost:9200"

# Servidor
PORT=3001
```

### Variables de Entorno (Frontend)

Crea un archivo `.env.local` en el directorio `frontend` con el siguiente contenido:

```env
NEXT_PUBLIC_API_URL=http://localhost:3001
```

---

## ğŸ“Š Performance

| OperaciÃ³n | Tiempo | Notas |
|-----------|--------|-------|
| BÃºsqueda SPARQL | 200-500ms | Fuseki |
| BÃºsqueda Elasticsearch | 10-50ms | 10-20x mÃ¡s rÃ¡pido |
| Autocompletado | 5-15ms | Ultra-rÃ¡pido |
| Upload OWL | 1-5s | Depende del tamaÃ±o |
| IndexaciÃ³n | 100-500ms | AutomÃ¡tica |

---

## ğŸ”’ Seguridad

### ProducciÃ³n
- Cambiar contraseÃ±as por defecto
- Configurar CORS apropiadamente
- Usar HTTPS
- Implementar autenticaciÃ³n
- Rate limiting en API

### Desarrollo
- ContraseÃ±as en `.env`
- No commitear secrets
- Usar variables de entorno

---

## ğŸ“± PWA - Funcionalidad Offline

### CaracterÃ­sticas
- **Service Worker**: CachÃ© inteligente
- **IndexedDB**: Almacenamiento local
- **Sync Manager**: SincronizaciÃ³n automÃ¡tica
- **Manifest**: Instalable como app

### Uso Offline
1. La app cachea automÃ¡ticamente
2. BÃºsquedas usan cachÃ© local
3. Uploads se guardan en IndexedDB
4. Al reconectar, sincroniza automÃ¡ticamente

---

## ğŸŒ InternacionalizaciÃ³n (i18n)

### Idiomas Soportados
- ğŸ‡ªğŸ‡¸ **EspaÃ±ol** (por defecto)
- ğŸ‡¬ğŸ‡§ **InglÃ©s**

### Agregar Nuevo Idioma

**Backend**:
1. Crear `src/i18n/fr/messages.json`
2. Traducir todos los mensajes

**Frontend**:
1. Crear `public/locales/fr/common.json`
2. Traducir todas las claves
3. Actualizar `next-i18next.config.js`:
```javascript
locales: ['es', 'en', 'fr']
```

---

## ğŸ§ª Testing

```bash
# Backend
cd backend
npm run test

# Frontend
cd frontend
npm run test
```

---

## ğŸ“¦ Build para ProducciÃ³n

### Backend
```bash
cd backend
npm run build
npm run start:prod
```

### Frontend
```bash
cd frontend
npm run build
npm start
```

---

## ğŸ”„ Flujo de Trabajo de Desarrollo

### Desarrollo TÃ­pico
1. Inicia Docker: `cd backend && docker-compose up -d`
2. Inicia backend: `cd backend && npm run start:dev`
3. Inicia frontend: `cd frontend && npm run dev`
4. Accede a http://localhost:3000

### DespuÃ©s de Cambios en el Schema de Prisma
```bash
cd backend
npx prisma generate  # Regenerar cliente
npx prisma db push   # Aplicar cambios a la BD
```

### Limpieza de Archivos Temporales
Los archivos subidos temporalmente se limpian automÃ¡ticamente despuÃ©s de ser procesados. Si necesitas limpiar manualmente:
```bash
cd backend
rm -rf uploads/*
```

---

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

---

## ğŸ‘¥ Autores

- **Brandon Garcia** - Desarrollo completo
